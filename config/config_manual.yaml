accumulate_grad: 1
batch_size: 32
beam_size: 1
cache_dir: ../data/cache
ckpt_freq:
- 500
- 2000
- 5000
ckpt_save_num: 1
ckptpath: ''
config_manual: config/config_manual.yaml
config_trainer: config/config_trainer.yaml
filepath: ''
input_type: c1
lr: 3.0e-05
max_epochs: 50
max_len: 128
max_steps: null
model_type: gpt2
num_workers: 0
optimizer: AdamW
plugins: null
precision: 32
prev_model: null
proctitle: null
save_filename: /mnt/md0/hyeon/checkpoints/FLES_unsegen/
seed: null
tbpath: null
train_file: ../data/Data_processed/Data_split1_processed_train.csv
training_type: type1
trmodel: /home/mnt/hyeon/1.Dataset/WMT22/APE/fairseq_run/ckpt/tr-pub-dist-all
use_cache: false
valid_file: ../data/Data_processed/Data_split1_processed_valid.csv
warmup_ratio: 0.1
